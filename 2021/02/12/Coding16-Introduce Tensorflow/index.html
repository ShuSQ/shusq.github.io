<!DOCTYPE html>
<html lang="en">
    <!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1, maximum-scale=1">
  
  <title>Coding16 - Introduce Tensorflow - Shu-Creative Computing</title>
  
    <link rel="shortcut icon" href="/favicon.ico">
  
  
    <link rel='manifest' href='/manifest.json'>
  

  
<link rel="stylesheet" href="/css/var.css">

  
<link rel="stylesheet" href="/css/main.css">

  
<link rel="stylesheet" href="/css/cursor.css">

  
<link rel="stylesheet" href="/css/typography.css">

  
<link rel="stylesheet" href="/css/components.css">

  
<link rel="stylesheet" href="/css/nav.css">

  
<link rel="stylesheet" href="/css/paginator.css">

  
<link rel="stylesheet" href="/css/footer.css">

  
<link rel="stylesheet" href="/css/post-list.css">

  
  
  
<link rel="stylesheet" href="/css/post.css">

  

<meta name="generator" content="Hexo 5.2.0"></head>


    <body>
        <nav id="theme-nav">
    <div class="inner">
        <a class="title" href="/">Shu&#39;s Blog</a>
        <div class="nav-arrow"></div>
        <div class="nav-items">
            <a class="nav-item nav-item-home" href="/">Home</a>
            
            
            <a class="nav-item" href="/categories/essays">Thinking</a>
            
            
            
            <a class="nav-item" href="/categories/pcomp">Pcomp&amp;AVCE</a>
            
            
            
            <a class="nav-item" href="/categories/coding">Coding</a>
            
            
            
            <a class="nav-item" href="/categories/portfolio">Portfolio</a>
            
            
            
            <a class="nav-item" href="/contact">About</a>
            
            
            
            <a class="nav-item nav-item-github nav-item-icon" href="https://github.com/ShuSQ" target="_blank">&nbsp;</a>
            
            
            
            <a class="nav-item nav-item-codepen nav-item-icon" href="https://codepen.io/shusq" target="_blank">&nbsp;</a>
            
            
            
            <a class="nav-item nav-item-patreon nav-item-icon" href="https://www.instagram.com/cheese_shu/" target="_blank">&nbsp;</a>
            
            
        </div>
    </div>
</nav>
        <article class="post">
    <div class="meta">
        
        <div class="date" id="date">
            
            
            <span>February</span>
            
            
            
            
            
            
            
            
            
            
            
            <span>12,</span>
            <span>2021</span>
        </div>
        

        <h2 class="title">Coding16 - Introduce Tensorflow</h2>
    </div>

    <div class="divider"></div>

    <div class="content">
        <blockquote>
<p>Learn machine learning through TensorFlow, and achieve a simple NST work.</p>
</blockquote>
<h3 id="What-is-TensorFlow"><a href="#What-is-TensorFlow" class="headerlink" title="What is TensorFlow?"></a>What is TensorFlow?</h3><p>Tensorflow is a machine learning framework, created by Google; it can be used to design, build and train deep.</p>
<p><strong>What is tensorï¼Ÿ</strong></p>
<p>We can compare a tensor to a video file. A video consists of a series of frames, and each frame includes many individual color values. The collection of frames can be regarded as a tensor. Each individual color value can be regarded as a scalar, and a group of color values can be regarded as a vector, for example, RGBA can be regarded as a 4D vector (xyzw). Vector blocks can be thought as tensors.</p>
<p>Another simple explanation: tensors are data. They can be lists of numbers or vectors of any dimensionality. They can be multidimensional data blocks, such as a set of images or videos. Tensorflow essentially allows users to construct a large amount of digital data, and then use CPU, GPU and even TPU to process the data, but in essence it is still a large number of multiplications and additions.</p>
<p>This is a small exercise to implement NST using Python and tensorflow, you also can find it in <a target="_blank" rel="noopener" href="https://colab.research.google.com/drive/1GGarjLCkHIlABWpV1O6Bu7SYp_4mm0PN?usp=sharing">colab</a>:</p>
<blockquote>
<p>Import our libraries and modules.</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> IPython.display <span class="keyword">as</span> display</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> matplotlib <span class="keyword">as</span> mpl</span><br><span class="line">mpl.rcParams[<span class="string">&#x27;figure.figsize&#x27;</span>] = (<span class="number">12</span>, <span class="number">12</span>)</span><br><span class="line">mpl.rcParams[<span class="string">&#x27;axes.grid&#x27;</span>] = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> PIL.Image</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> functools</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">tensor_to_image</span>(<span class="params">tensor</span>):</span></span><br><span class="line">  tensor = tensor * <span class="number">255</span></span><br><span class="line">  tensor = np.array(tensor, dtype = np.uint8)</span><br><span class="line">  <span class="keyword">if</span> np.ndim(tensor) &gt; <span class="number">3</span>:</span><br><span class="line">    <span class="keyword">assert</span> tensor.shape[<span class="number">0</span>] == <span class="number">1</span></span><br><span class="line">    tensor = tensor[<span class="number">0</span>]</span><br><span class="line">  <span class="keyword">return</span> PIL.Image.fromarray(tensor)</span><br></pre></td></tr></table></figure>

<blockquote>
<p>Choose our style image and content image.</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">content_path = tf.keras.utils.get_file(<span class="string">&#x27;content.jpg&#x27;</span>, <span class="string">&#x27;https://mywowo.net/media/images/cache/londra_tower_bridge_01_introduzione_jpg_1200_630_cover_85.jpg&#x27;</span>)</span><br><span class="line">style_path = tf.keras.utils.get_file(<span class="string">&#x27;style.jpg&#x27;</span>, <span class="string">&#x27;https://resources.matcha-jp.com/resize/720x2000/2017/10/14-38660.jpeg&#x27;</span>)</span><br><span class="line"><span class="comment"># style_path = tf.keras.utils.get_file(&#x27;style.jpg&#x27;, &#x27;https://pic3.zhimg.com/80/v2-fe222a9c96b35f9d86da39122777c8d2_1440w.jpg&#x27;)</span></span><br></pre></td></tr></table></figure>

<blockquote>
<p>Define a function to load images, and limit the max size under 512px.</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">load_img</span>(<span class="params">path_to_img</span>):</span></span><br><span class="line">  max_dim = <span class="number">512</span></span><br><span class="line">  img = tf.io.read_file(path_to_img)</span><br><span class="line">  img = tf.image.decode_image(img, channels=<span class="number">3</span>)</span><br><span class="line">  img = tf.image.convert_image_dtype(img, tf.float32)</span><br><span class="line"></span><br><span class="line">  shape = tf.cast(tf.shape(img)[:<span class="number">-1</span>], tf.float32)</span><br><span class="line">  long_dim = <span class="built_in">max</span>(shape)</span><br><span class="line">  scale = max_dim / long_dim</span><br><span class="line"></span><br><span class="line">  new_shape = tf.cast(shape * scale, tf.int32)</span><br><span class="line"></span><br><span class="line">  img = tf.image.resize(img, new_shape)</span><br><span class="line">  img = img[tf.newaxis, :]</span><br><span class="line">  <span class="keyword">return</span> img</span><br></pre></td></tr></table></figure>

<blockquote>
<p>Create a simple function to display image.</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">imshow</span>(<span class="params">image, title=<span class="literal">None</span></span>):</span></span><br><span class="line">  <span class="keyword">if</span> <span class="built_in">len</span>(image.shape) &gt; <span class="number">3</span>:</span><br><span class="line">   image = tf.squeeze(image, axis=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">  plt.imshow(image)</span><br><span class="line">  <span class="keyword">if</span> title:</span><br><span class="line">    plt.title(title)</span><br><span class="line"></span><br><span class="line">content_image = load_img(content_path)</span><br><span class="line">style_image = load_img(style_path)</span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">1</span>, <span class="number">2</span>, <span class="number">1</span>)</span><br><span class="line">imshow(content_image, <span class="string">&#x27;Content Image&#x27;</span>)</span><br><span class="line">plt.subplot(<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>)</span><br><span class="line">imshow(style_image, <span class="string">&#x27;Style Image&#x27;</span>)</span><br></pre></td></tr></table></figure>

<p><img src="https://miro.medium.com/max/655/1*QaqJoUEn5voodqq4Uw2UhQ.png"></p>
<blockquote>
<p>Use TF-Hub to make Fast Neural Style Transfer.</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow_hub <span class="keyword">as</span> hub</span><br><span class="line">hub_module = hub.load(<span class="string">&#x27;https://tfhub.dev/google/magenta/arbitrary-image-stylization-v1-256/1&#x27;</span>)</span><br><span class="line">stylized_image = hub_module(tf.constant(content_image), tf.constant(style_image))[<span class="number">0</span>]</span><br><span class="line">tensor_to_image(stylized_image)</span><br></pre></td></tr></table></figure>

<p><img src="https://miro.medium.com/max/346/1*FdQ_uZVgb29oA-iDGLUIuQ.png"></p>
<blockquote>
<p>We can use intermediate layers to get <em>content</em> and <em>style</em> representations of the image; we can use VGG19 to define content and style representations.</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">x = tf.keras.applications.vgg19.preprocess_input(content_image*<span class="number">255</span>)</span><br><span class="line">x = tf.image.resize(x, (<span class="number">224</span>, <span class="number">224</span>))</span><br><span class="line">vgg = tf.keras.applications.VGG19(include_top=<span class="literal">True</span>, weights=<span class="string">&#x27;imagenet&#x27;</span>)</span><br><span class="line">prediction_probabilities = vgg(x)</span><br><span class="line">prediction_probabilities.shape</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">predicted_top_5 = tf.keras.applications.vgg19.decode_predictions(prediction_probabilities.numpy())[<span class="number">0</span>]</span><br><span class="line">[(class_name, prob) <span class="keyword">for</span> (number, class_name, prob) <span class="keyword">in</span> predicted_top_5]</span><br></pre></td></tr></table></figure>

<blockquote>
<p>Loading a <code>VGG19</code> without the classification head, and list the layer names.</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">vgg = tf.keras.applications.VGG19(include_top=<span class="literal">False</span>, weights=<span class="string">&#x27;imagenet&#x27;</span>)</span><br><span class="line"></span><br><span class="line">print()</span><br><span class="line"><span class="keyword">for</span> layer <span class="keyword">in</span> vgg.layers:</span><br><span class="line">  print(layer.name)</span><br></pre></td></tr></table></figure>

<blockquote>
<p>Choose intermediate layers from the network to represent the style and content of the image.</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">content_layers = [<span class="string">&#x27;block5_conv2&#x27;</span>]</span><br><span class="line"></span><br><span class="line">style_layers = [<span class="string">&#x27;block1_conv1&#x27;</span>,</span><br><span class="line">                <span class="string">&#x27;block2_conv1&#x27;</span>,</span><br><span class="line">                <span class="string">&#x27;block3_conv1&#x27;</span>,</span><br><span class="line">                <span class="string">&#x27;block4_conv1&#x27;</span>,</span><br><span class="line">                <span class="string">&#x27;block5_conv1&#x27;</span>]</span><br><span class="line">              </span><br><span class="line">num_content_layers = <span class="built_in">len</span>(content_layers)</span><br><span class="line">num_style_layers = <span class="built_in">len</span>(style_layers)</span><br></pre></td></tr></table></figure>

<blockquote>
<p>Extract the intermediate layer values using the Keras functional API <code>tf.keras.applications</code>.</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">vgg_layers</span>(<span class="params">layer_names</span>):</span></span><br><span class="line">  <span class="string">&quot;&quot;&quot;Creates a vgg model that returns a list of intermediate output values.&quot;&quot;&quot;</span></span><br><span class="line">  <span class="comment"># Load our model and pretrained VGG, trained on tmagenet data</span></span><br><span class="line">  vgg = tf.keras.applications.VGG19(include_top=<span class="literal">False</span>, weights=<span class="string">&#x27;imagenet&#x27;</span>)</span><br><span class="line">  vgg.trainable = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line">  outputs = [vgg.get_layer(name).output <span class="keyword">for</span> name <span class="keyword">in</span> layer_names]</span><br><span class="line"></span><br><span class="line">  model = tf.keras.Model([vgg.<span class="built_in">input</span>], outputs)</span><br><span class="line">  <span class="keyword">return</span> model</span><br></pre></td></tr></table></figure>

<blockquote>
<p>Create the model.</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">style_extractor = vgg_layers(style_layers)</span><br><span class="line">style_outputs = style_extractor(style_image*<span class="number">255</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Look at the statistics of each layer&#x27;s output</span></span><br><span class="line"><span class="keyword">for</span> name, output <span class="keyword">in</span> <span class="built_in">zip</span>(style_layers, style_outputs):</span><br><span class="line">  print(name)</span><br><span class="line">  print(<span class="string">&quot;  shape: &quot;</span>, output.numpy().shape)</span><br><span class="line">  print(<span class="string">&quot;  min: &quot;</span>, output.numpy().<span class="built_in">min</span>())</span><br><span class="line">  print(<span class="string">&quot;  max: &quot;</span>, output.numpy().<span class="built_in">max</span>())</span><br><span class="line">  print(<span class="string">&quot;  mean: &quot;</span>, output.numpy().mean())</span><br><span class="line">  print()</span><br></pre></td></tr></table></figure>

<blockquote>
<p>The style of images can be described by the means and correlations across the different feature maps. We can <code>tf.linalg.einsum</code> function to achieve that.</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">gram_matrix</span>(<span class="params">input_tensor</span>):</span></span><br><span class="line">  result = tf.linalg.einsum(<span class="string">&#x27;bijc,bijd-&gt;bcd&#x27;</span>, input_tensor, input_tensor)</span><br><span class="line">  input_shape = tf.shape(input_tensor)</span><br><span class="line">  num_locations = tf.cast(input_shape[<span class="number">1</span>]*input_shape[<span class="number">2</span>], tf.float32)</span><br><span class="line">  <span class="keyword">return</span> result/(num_locations)</span><br></pre></td></tr></table></figure>

<blockquote>
<p>Build a model that returns the style and content tensors, extract style and content.</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">StyleContentModel</span>(<span class="params">tf.keras.models.Model</span>):</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, style_layers, content_layers</span>):</span></span><br><span class="line">    <span class="built_in">super</span>(StyleContentModel, self).__init__()</span><br><span class="line">    self.vgg = vgg_layers(style_layers + content_layers)</span><br><span class="line">    self.style_layers = style_layers</span><br><span class="line">    self.content_layers = content_layers</span><br><span class="line">    self.num_style_layers = <span class="built_in">len</span>(style_layers)</span><br><span class="line">    self.vgg.trainable = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">call</span>(<span class="params">self, inputs</span>):</span></span><br><span class="line">    <span class="string">&quot;Expects float input in [0, 1]&quot;</span></span><br><span class="line">    inputs = inputs*<span class="number">255.0</span></span><br><span class="line">    preprocessed_input = tf.keras.applications.vgg19.preprocess_input(inputs)</span><br><span class="line">    outputs = self.vgg(preprocessed_input)</span><br><span class="line">    style_outputs, content_outputs = (outputs[:self.num_style_layers],</span><br><span class="line">                                      outputs[self.num_style_layers:])</span><br><span class="line">    </span><br><span class="line">    style_outputs = [gram_matrix(style_output)</span><br><span class="line">                     <span class="keyword">for</span> style_output <span class="keyword">in</span> style_outputs]</span><br><span class="line"></span><br><span class="line">    content_dict = &#123;content_name: value</span><br><span class="line">                    <span class="keyword">for</span> content_name, value</span><br><span class="line">                    <span class="keyword">in</span> <span class="built_in">zip</span>(self.content_layers, content_outputs)&#125;</span><br><span class="line"></span><br><span class="line">    style_dict = &#123;style_name: value</span><br><span class="line">                 <span class="keyword">for</span> style_name, value</span><br><span class="line">                 <span class="keyword">in</span> <span class="built_in">zip</span>(self.style_layers, style_outputs)&#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> &#123;<span class="string">&#x27;content&#x27;</span>: content_dict, <span class="string">&#x27;style&#x27;</span>: style_dict&#125;</span><br></pre></td></tr></table></figure>

<blockquote>
<p>This model returns the gram matrix(style) of the <code>style_layers</code> and content of the <code>content_layers</code>.</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">extractor = StyleContentModel(style_layers, content_layers)</span><br><span class="line"></span><br><span class="line">results = extractor(tf.constant(content_image))</span><br><span class="line"></span><br><span class="line">print(<span class="string">&#x27;Styles:&#x27;</span>)</span><br><span class="line"><span class="keyword">for</span> name, output <span class="keyword">in</span> <span class="built_in">sorted</span>(results[<span class="string">&#x27;style&#x27;</span>].items()):</span><br><span class="line">  print(<span class="string">&quot;  &quot;</span>, name)</span><br><span class="line">  print(<span class="string">&quot;  shape: &quot;</span>, output.numpy().shape)</span><br><span class="line">  print(<span class="string">&quot;  min: &quot;</span>, output.numpy().<span class="built_in">min</span>())</span><br><span class="line">  print(<span class="string">&quot;  max: &quot;</span>, output.numpy().<span class="built_in">max</span>())</span><br><span class="line">  print(<span class="string">&quot;  mean: &quot;</span>, output.numpy().mean())</span><br><span class="line">  print()</span><br><span class="line"></span><br><span class="line">print(<span class="string">&quot;Contents:&quot;</span>)</span><br><span class="line"><span class="keyword">for</span> name, output <span class="keyword">in</span> <span class="built_in">sorted</span>(results[<span class="string">&#x27;content&#x27;</span>].items()):</span><br><span class="line">  print(<span class="string">&quot;  &quot;</span>, name)</span><br><span class="line">  print(<span class="string">&quot;  shape: &quot;</span>, output.numpy().shape)</span><br><span class="line">  print(<span class="string">&quot;  min: &quot;</span>, output.numpy().<span class="built_in">min</span>())</span><br><span class="line">  print(<span class="string">&quot;  max: &quot;</span>, output.numpy().<span class="built_in">max</span>())</span><br><span class="line">  print(<span class="string">&quot;  mean: &quot;</span>, output.numpy().mean())</span><br></pre></td></tr></table></figure>

<blockquote>
<p>Calculating the mean square error for imageâ€™s output relative to each target, then take the weighted sum of these losses.</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">style_targets = extractor(style_image)[<span class="string">&#x27;style&#x27;</span>]</span><br><span class="line">content_targets = extractor(content_image)[<span class="string">&#x27;content&#x27;</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># Define a `tf.Variable` to contain the image to optimize.</span></span><br><span class="line">image = tf.Variable(content_image)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Define a function to keep the pixel values between 0 and 1.</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">clip_0_1</span>(<span class="params">image</span>):</span></span><br><span class="line">  <span class="keyword">return</span> tf.clip_by_value(image, clip_value_min = <span class="number">0.0</span>, clip_value_max = <span class="number">1.0</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Create an optimizer with `Adam`.</span></span><br><span class="line">opt = tf.optimizers.Adam(learning_rate=<span class="number">0.02</span>, beta_1=<span class="number">0.99</span>, epsilon=<span class="number">1e-1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Use a weighted combination of the two losses to get the total loss.</span></span><br><span class="line">style_weight = <span class="number">1e-2</span></span><br><span class="line">content_weight=<span class="number">1e4</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">style_content_loss</span>(<span class="params">outputs</span>):</span></span><br><span class="line">  style_outputs = outputs[<span class="string">&#x27;style&#x27;</span>]</span><br><span class="line">  content_outputs = outputs[<span class="string">&#x27;content&#x27;</span>]</span><br><span class="line">  style_loss = tf.add_n([tf.reduce_mean((style_outputs[name]-style_targets[name])**<span class="number">2</span>)</span><br><span class="line">                         <span class="keyword">for</span> name <span class="keyword">in</span> style_outputs.keys()])</span><br><span class="line">  style_loss *= style_weight / num_style_layers</span><br><span class="line"></span><br><span class="line">  content_loss = tf.add_n([tf.reduce_mean((content_outputs[name]-content_targets[name])**<span class="number">2</span>)</span><br><span class="line">                           <span class="keyword">for</span> name <span class="keyword">in</span> content_outputs.keys()])</span><br><span class="line">  content_loss *= content_weight / num_content_layers</span><br><span class="line">  loss = style_loss + content_loss</span><br><span class="line">  <span class="keyword">return</span> loss</span><br></pre></td></tr></table></figure>

<blockquote>
<p>Use <code>tf.GradientTape</code> to update the image.</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@tf.function()</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train_step</span>(<span class="params">image</span>):</span></span><br><span class="line">  <span class="keyword">with</span> tf.GradientTape() <span class="keyword">as</span> tape:</span><br><span class="line">    outputs = extractor(image)</span><br><span class="line">    loss = style_content_loss(outputs)</span><br><span class="line"></span><br><span class="line">  grad = tape.gradient(loss, image)</span><br><span class="line">  opt.apply_gradients([(grad, image)])</span><br><span class="line">  image.assign(clip_0_1(image))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Run steps to test by 5 times</span></span><br><span class="line"></span><br><span class="line">train_step(image)</span><br><span class="line">train_step(image)</span><br><span class="line">train_step(image)</span><br><span class="line">train_step(image)</span><br><span class="line">train_step(image)</span><br><span class="line">tensor_to_image(image)</span><br></pre></td></tr></table></figure>

<p><img src="https://miro.medium.com/max/500/1*eybSeX4Dz7gA8LoV2H2FgA.png"></p>
<blockquote>
<p>Perform a longer optimization.</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> time</span><br><span class="line">start = time.time()</span><br><span class="line"></span><br><span class="line">epochs = <span class="number">10</span></span><br><span class="line">steps_per_epoch = <span class="number">50</span></span><br><span class="line"></span><br><span class="line">step = <span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> n <span class="keyword">in</span> <span class="built_in">range</span>(epochs):</span><br><span class="line">  <span class="keyword">for</span> m <span class="keyword">in</span> <span class="built_in">range</span>(steps_per_epoch):</span><br><span class="line">    step += <span class="number">1</span></span><br><span class="line">    train_step(image)</span><br><span class="line">    print(<span class="string">&quot;.&quot;</span>, end=<span class="string">&#x27;&#x27;</span>)</span><br><span class="line">  display.clear_output(wait=<span class="literal">True</span>)</span><br><span class="line">  display.display(tensor_to_image(image))</span><br><span class="line">  print(<span class="string">&quot;Train step: &#123;&#125;&quot;</span>.<span class="built_in">format</span>(step))</span><br><span class="line"></span><br><span class="line">end = time.time()</span><br><span class="line">print(<span class="string">&quot;Total time: &#123;:.1f&#125;&quot;</span>.<span class="built_in">format</span>(end-start))</span><br></pre></td></tr></table></figure>

<p><img src="https://miro.medium.com/max/500/1*tWWQNIoqBCf_4Qg-xBRg1Q.png"></p>
<blockquote>
<p>It produces alot of high frequency artifacts. Using an explicit regularization term to decrease those.</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">high_pass_x_y</span>(<span class="params">image</span>):</span></span><br><span class="line">  x_var = image[:,:,<span class="number">1</span>:,:] - image[:,:,:<span class="number">-1</span>,:]</span><br><span class="line">  y_var = image[:,<span class="number">1</span>:,:,:] - image[:,:<span class="number">-1</span>,:,:]</span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> x_var, y_var</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">x_deltas, y_deltas = high_pass_x_y(content_image)</span><br><span class="line"></span><br><span class="line">plt.figure(figsize=(<span class="number">14</span>,<span class="number">10</span>))</span><br><span class="line">plt.subplot(<span class="number">2</span>,<span class="number">2</span>,<span class="number">1</span>)</span><br><span class="line">imshow(clip_0_1(<span class="number">2</span>*y_deltas+<span class="number">0.5</span>), <span class="string">&quot;Horizontal Deltas: Original&quot;</span>)</span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">2</span>,<span class="number">2</span>,<span class="number">2</span>)</span><br><span class="line">imshow(clip_0_1(<span class="number">2</span>*x_deltas+<span class="number">0.5</span>), <span class="string">&quot;Vertical Deltas: Original&quot;</span>)</span><br><span class="line"></span><br><span class="line">x_deltas, y_deltas = high_pass_x_y(image)</span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">2</span>,<span class="number">2</span>,<span class="number">3</span>)</span><br><span class="line">imshow(clip_0_1(<span class="number">2</span>*y_deltas+<span class="number">0.5</span>), <span class="string">&quot;Horizontal Deltas: Styled&quot;</span>)</span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">2</span>,<span class="number">2</span>,<span class="number">4</span>)</span><br><span class="line">imshow(clip_0_1(<span class="number">2</span>*x_deltas+<span class="number">0.5</span>), <span class="string">&quot;Vertical Deltas: Styled&quot;</span>)</span><br></pre></td></tr></table></figure>

<p><img src="https://miro.medium.com/max/823/1*VdYCwKIAuXrpT3_rqWjVzw.png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">plt.figure(figsize=(<span class="number">14</span>,<span class="number">10</span>))</span><br><span class="line"></span><br><span class="line">sobel = tf.image.sobel_edges(content_image)</span><br><span class="line">plt.subplot(<span class="number">1</span>,<span class="number">2</span>,<span class="number">1</span>)</span><br><span class="line">imshow(clip_0_1(sobel[...,<span class="number">0</span>]/<span class="number">4</span>+<span class="number">0.5</span>), <span class="string">&quot;Horizontal Sobel-edges&quot;</span>)</span><br><span class="line">plt.subplot(<span class="number">1</span>,<span class="number">2</span>,<span class="number">2</span>)</span><br><span class="line">imshow(clip_0_1(sobel[...,<span class="number">1</span>]/<span class="number">4</span>+<span class="number">0.5</span>), <span class="string">&quot;Vertical Sobel-edges&quot;</span>)</span><br></pre></td></tr></table></figure>

<p><img src="https://miro.medium.com/max/499/1*7mObZCpyWCaY17g-n0k2QQ.png"></p>
<blockquote>
<p>The regularization loss associated with this is the sum of the squares of the values.</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">total_variation_loss</span>(<span class="params">image</span>):</span></span><br><span class="line">  x_deltas, y_deltas = high_pass_x_y(image)</span><br><span class="line">  <span class="keyword">return</span> tf.reduce_sum(tf.<span class="built_in">abs</span>(x_deltas)) + tf.reduce_sum(tf.<span class="built_in">abs</span>(y_deltas))</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">total_variation_loss(image).numpy()</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tf.image.total_variation(image).numpy()</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Rerun the Optimization.</span></span><br><span class="line">total_variation_weight = <span class="number">30</span></span><br><span class="line"></span><br><span class="line"><span class="meta">@tf.function()</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train_step</span>(<span class="params">image</span>):</span></span><br><span class="line">  <span class="keyword">with</span> tf.GradientTape() <span class="keyword">as</span> tape:</span><br><span class="line">    outputs = extractor(image)</span><br><span class="line">    loss = style_content_loss(outputs)</span><br><span class="line">    loss += total_variation_weight*tf.image.total_variation(image)</span><br><span class="line"></span><br><span class="line">  grad = tape.gradient(loss, image)</span><br><span class="line">  opt.apply_gradients([(grad, image)])</span><br><span class="line">  image.assign(clip_0_1(image))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Reinitialize the optimization variable.</span></span><br><span class="line">image = tf.Variable(content_image)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Rerun the optimization.</span></span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line">start = time.time()</span><br><span class="line"></span><br><span class="line">epochs = <span class="number">10</span></span><br><span class="line">steps_per_epoch = <span class="number">50</span></span><br><span class="line"></span><br><span class="line">step = <span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> n <span class="keyword">in</span> <span class="built_in">range</span>(epochs):</span><br><span class="line">  <span class="keyword">for</span> m <span class="keyword">in</span> <span class="built_in">range</span>(steps_per_epoch):</span><br><span class="line">    step += <span class="number">1</span></span><br><span class="line">    train_step(image)</span><br><span class="line">    print(<span class="string">&quot;.&quot;</span>, end=<span class="string">&#x27;&#x27;</span>)</span><br><span class="line">  display.clear_output(wait=<span class="literal">True</span>)</span><br><span class="line">  display.display(tensor_to_image(image))</span><br><span class="line">  print(<span class="string">&quot;Train step: &#123;&#125;&quot;</span>.<span class="built_in">format</span>(step))</span><br><span class="line"></span><br><span class="line">end = time.time()</span><br><span class="line">print(<span class="string">&quot;Total time: &#123;:.1f&#125;&quot;</span>.<span class="built_in">format</span>(end-start))</span><br></pre></td></tr></table></figure>

<p><img src="https://miro.medium.com/max/512/1*Arrt09oqATYX1LFEOT7BhQ.png"></p>

    </div>

    <div class="about">
        <h1>About this Post</h1>
        <p>This post is written by Siqi Shu, licensed under <a
                target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc/4.0">CC BY-NC 4.0</a>.</p>
    </div>
</article>
        <footer>
    <div class="inner">
        <div class="links">
            
            <div class="group">
                <h4 class="title">æ·±æ™ºä¸€ç‰© çœ¾éš±çš†è®Š</h4>
                
            </div>
            
        </div>
        &copy; 2024 Siqi Shu<br />
        Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
</footer>


        
<script src="/js/main.js"></script>

        
<script src="/js/kursor.js"></script>

        
<script src="/js/run.js"></script>


    </body>
</html>
